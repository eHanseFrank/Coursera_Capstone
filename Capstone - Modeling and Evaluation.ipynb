{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": "import pandas as pd\nimport numpy as np\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nfrom sklearn import preprocessing"
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": "from sklearn.metrics import f1_score\nfrom sklearn.metrics import jaccard_score"
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "(194673, 5)"
                    },
                    "execution_count": 4,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "df = pd.read_csv('mod_df.csv')\ndf.shape"
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "(194673, 4)"
                    },
                    "execution_count": 5,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "# The Modeling-Evaluation-Split may have the ratio of 3:7. We retrieve a random selection of rows from the working data.\n# We accomplish this first split also using scit-learn train-test-split function\n# Notice: For better modeling, take ROADCOND, WEATHER, LIGHTCOND as categorical data and apply One-Hot-Encoding. (But not Junctiontype)\n# Define feature set\nFeature = df[['JUNCTIONTYPE','WEATHER','ROADCOND','LIGHTCOND']]\nX = Feature\nX.shape"
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": "# Define our classifier label\ny = df['SEVERITYCODE.1']"
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [],
            "source": "# Apply test-train-split in order to get the Modeling-Evaluation split\nX_model, X_eval, y_model, y_eval = train_test_split( X, y, test_size=0.3, random_state=4)"
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "(136271, 4)"
                    },
                    "execution_count": 8,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "X_model.shape"
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [],
            "source": "# Apply test-train-split in order to get the train and test data\nX_train, X_test, y_train, y_test = train_test_split( X_model, y_model, test_size=0.2, random_state=4)"
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "(109016, 4)"
                    },
                    "execution_count": 10,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "X_train.shape\n"
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [],
            "source": "# We normalize the data after the train test split.\nX_train = preprocessing.StandardScaler().fit(X_train).transform(X_train)"
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "[0.69649606 0.69649606 0.69649606 0.69649606 0.69612915 0.69612915\n 0.69609246 0.69605577 0.68189323]\n[0.57189258 0.57189258 0.57189258 0.57189258 0.57218934 0.57218934\n 0.57210386 0.57215367 0.58065075]\n[0.69649606 0.69649606 0.69649606 0.69649606 0.69605109 0.69605109\n 0.69602554 0.69597769 0.67878182]\n"
                }
            ],
            "source": "# We use the training data to optimize K (depth of tree)\nKs = 10\nmean_acc_dt = np.zeros((Ks-1))\nstd_acc_dt = np.zeros((Ks-1))\njac_sc_dt = np.zeros((Ks-1))\nf1_sc_dt = np.zeros((Ks-1))\n\nfor n in range(1,Ks):\n    \n    #Train Model and Predict  \n    collTree = DecisionTreeClassifier(criterion=\"entropy\", max_depth = n)\n    collTree.fit(X_train,y_train)\n    yhat_dt=collTree.predict(X_test)\n    mean_acc_dt[n-1] = metrics.accuracy_score(y_test, yhat_dt)\n    f1_sc_dt[n-1] = f1_score(y_test, yhat_dt, average='weighted')\n    jac_sc_dt[n-1] = jaccard_score(y_test, yhat_dt)\n    \n    std_acc_dt[n-1]=np.std(yhat_dt==y_test)/np.sqrt(yhat_dt.shape[0])\n\nprint(mean_acc_dt)\nprint(f1_sc_dt)\nprint(jac_sc_dt)\n"
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "array([1.26838864, 1.26838864, 1.26838864, 1.26838864, 1.26824043,\n       1.26824043, 1.2681294 , 1.26813136, 1.25943256])"
                    },
                    "execution_count": 20,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "# Using different k does not seems to have a huge impact. We calculate the sum of f1 and jac values to identify the\n# best k\nresult = jac_sc_dt + f1_sc_dt\nresult"
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "DecisionTreeClassifier(criterion='entropy', max_depth=4)"
                    },
                    "execution_count": 21,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "# We can recognize that for example the 4th value meaning k=4 provides the highest score.\n# We will use this to create the optimal model\ncollTree = DecisionTreeClassifier(criterion=\"entropy\", max_depth = 4)\ncollTree.fit(X_train,y_train)"
        },
        {
            "cell_type": "code",
            "execution_count": 31,
            "metadata": {},
            "outputs": [],
            "source": "# collTree is a optimized Decision Tree model. We will apply it to the Evaluation Data\n# Normalize Evaluation Data\nX_eval = preprocessing.StandardScaler().fit(X_eval).transform(X_eval)\n"
        },
        {
            "cell_type": "code",
            "execution_count": 24,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "array([[-0.81754732,  0.2414237 ,  0.52548927, -0.59230676],\n       [ 0.25007932,  1.18498437,  0.52548927, -0.59230676],\n       [-0.81754732,  1.18498437,  0.52548927,  0.31793452],\n       [ 0.25007932,  1.18498437, -0.56931753,  0.31793452],\n       [ 0.25007932, -0.70213697, -0.56931753, -0.59230676]])"
                    },
                    "execution_count": 24,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "X_eval[0:5]"
        },
        {
            "cell_type": "code",
            "execution_count": 29,
            "metadata": {},
            "outputs": [],
            "source": "# The Predicted labels are calculated:\nyhat_test_2 = collTree.predict(X_eval)"
        },
        {
            "cell_type": "code",
            "execution_count": 26,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "0.5809904188654375"
                    },
                    "execution_count": 26,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "# Calculating the F1 Score\nf1_sc_test_2 = f1_score(y_eval, yhat_test_2, average='weighted')\nf1_sc_test_2"
        },
        {
            "cell_type": "code",
            "execution_count": 27,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "0.7034519365775145"
                    },
                    "execution_count": 27,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "# Calculating the Jaggard Score\njac_sc_test_2 = jaccard_score(y_eval, yhat_test_2)\njac_sc_test_2"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": ""
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "ds-ibm_lab",
            "language": "python",
            "name": "ds-ibm_lab"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.6.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}